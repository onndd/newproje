{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ü¶Ö AVCI - Y√ºksek Oran Avcƒ±sƒ± Eƒüitim Paneli v6.2.0 (Open Box Edition)\n",
        "**G√ºncelleme Notlarƒ±:**\n",
        "- **üéõÔ∏è A√ßƒ±k Hiperparametreler:** Optuna'nƒ±n kullandƒ±ƒüƒ± t√ºm ayarlar (√ñƒürenme hƒ±zƒ±, derinlik vb.) artƒ±k bu sayfada, g√∂z√ºn√ºn √∂n√ºnde. ƒ∞stediƒüin gibi deƒüi≈ütirip deneyebilirsin.\n",
        "- **Tam Kontrol:** Her ≈üeyi sen y√∂netiyorsun.",
        "\n---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. GitHub Deposunu √áek ve Kurulum Yap (Temiz Kurulum)\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# 1. K√∂k dizine d√∂n\n",
        "try:\n",
        "    os.chdir('/content')\n",
        "except:\n",
        "    pass\n",
        "\n",
        "# 2. Varsa eski projeyi Sƒ∞L (Her ≈üeyi sƒ±fƒ±rla ki eski hatalar kalmasƒ±n)\n",
        "if os.path.exists('newproje'):\n",
        "    print(\"Eski proje dosyalarƒ± temizleniyor...\")\n",
        "    shutil.rmtree('newproje')\n",
        "\n",
        "# 3. Sƒ±fƒ±rdan ƒ∞ndir\n",
        "print(\"Projeyi GitHub'dan sƒ±fƒ±rdan √ßekiyorum...\")\n",
        "!git clone https://github.com/onndd/newproje.git\n",
        "\n",
        "# 4. √áalƒ±≈üma dizinine gir\n",
        "if os.path.exists('newproje/avci'):\n",
        "    os.chdir('newproje/avci')\n",
        "    print(f\"‚úÖ Kurulum Ba≈üarƒ±lƒ±. √áalƒ±≈üma Dizini: {os.getcwd()}\")\n",
        "    \n",
        "    # --- VERƒ∞TABANI KURTARMA ---\n",
        "    drive_db_path = '/content/drive/MyDrive/newproje/avci/jetx.db'\n",
        "    local_db_path = 'jetx.db'\n",
        "    \n",
        "    if not os.path.exists('/content/drive'):\n",
        "        try:\n",
        "            from google.colab import drive\n",
        "            drive.mount('/content/drive')\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    if os.path.exists(drive_db_path):\n",
        "        print(f\"üîÑ Ger√ßek Veritabanƒ± Drive'dan kopyalanƒ±yor... ({os.path.getsize(drive_db_path)/1024/1024:.2f} MB)\")\n",
        "        shutil.copy(drive_db_path, local_db_path)\n",
        "        print(\"‚úÖ Veritabanƒ± g√ºncellendi.\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è UYARI: Drive'da 'jetx.db' bulunamadƒ±! Veritabanƒ± bo≈ü olabilir.\")\n",
        "else:\n",
        "    print(\"‚ùå HATA: ƒ∞ndirme ba≈üarƒ±sƒ±z oldu!\")\n",
        "\n",
        "print(\"GPU Durumu:\")\n",
        "!nvidia-smi\n",
        "\n",
        "# K√ºt√ºphane Kurulumlarƒ±\n",
        "!pip install optuna streamlit matplotlib pandas tensorflow hmmlearn plotly lightgbm\n",
        "print(\"Kurulum ve Hazƒ±rlƒ±k Tamamlandƒ±! Artƒ±k mod√ºller bulunabilir.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2. Veri Y√ºkleme ve Ayarlar\n",
        "import optuna\n",
        "import logging\n",
        "import sys\n",
        "import os\n",
        "\n",
        "optuna.logging.set_verbosity(optuna.logging.INFO)\n",
        "optuna.logging.get_logger(\"optuna\").addHandler(logging.StreamHandler(sys.stdout))\n",
        "\n",
        "try:\n",
        "    # Mod√ºlleri i√ße aktar (Absolute Import)\n",
        "    import train_avci\n",
        "    import models_avci\n",
        "    import model_ae_avci\n",
        "    import model_hmm_avci\n",
        "    import lightgbm as lgb\n",
        "    import numpy as np\n",
        "    from sklearn.metrics import confusion_matrix\n",
        "    \n",
        "    # Fonksiyonlarƒ± kƒ±sayol olarak al\n",
        "    load_and_prep = train_avci.load_and_prep\n",
        "    visualize_performance = train_avci.visualize_performance\n",
        "    get_scoring_params = train_avci.get_scoring_params\n",
        "    \n",
        "    print(\"‚úÖ Mod√ºller ba≈üarƒ±yla y√ºklendi!\")\n",
        "except ImportError as e:\n",
        "    print(f\"‚ùå HATA: Mod√ºl import hatasƒ±. Detay: {e}\")\n",
        "\n",
        "if 'load_and_prep' in locals():\n",
        "    try:\n",
        "        df = load_and_prep(limit=100000)\n",
        "        print(f\"Veri Hazƒ±r: {len(df)} satƒ±r. (S√ºtunlar: {len(df.columns)})\")\n",
        "    except Exception as e:\n",
        "         print(f\"‚ùå VERƒ∞ Y√úKLEME HATASI: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéõÔ∏è Optuna Hiperparametre Ayarlarƒ± (BEYƒ∞N)\n",
        "Buradaki deƒüerleri deƒüi≈ütirerek yapay zekanƒ±n arama alanƒ±nƒ± y√∂netebilirsin."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_optuna_for_target(target, epochs=30):\n",
        "    \"\"\"\n",
        "    Belirtilen hedef i√ßin Optuna optimizasyonunu Notebook i√ßinde √ßalƒ±≈ütƒ±rƒ±r.\n",
        "    B√∂ylece parametreleri G√ñREBƒ∞Lƒ∞RSƒ∞N.\n",
        "    \"\"\"\n",
        "    print(f\"\\nüöÄ {target}x Hedefi ƒ∞√ßin Eƒüitim Ba≈ülƒ±yor...\")\n",
        "    \n",
        "    # 1. Hedef S√ºtunu Hazƒ±rla\n",
        "    y_col = f'target_{str(target).replace(\".\",\"_\")}'\n",
        "    if y_col not in df.columns:\n",
        "        print(f\"‚ùå Hata: {y_col} s√ºtunu bulunamadƒ±!\")\n",
        "        return\n",
        "        \n",
        "    y_train = df[y_col].iloc[:split_idx]\n",
        "    y_val = df[y_col].iloc[split_idx:]\n",
        "    scoring = get_scoring_params(target)\n",
        "\n",
        "    # 2. OPTUNA OBJECTIVE FONKSƒ∞YONU (Parametreler Burada)\n",
        "    def objective(trial):\n",
        "        params = {\n",
        "            'objective': 'binary',\n",
        "            'metric': 'binary_logloss',\n",
        "            'verbosity': -1,\n",
        "            'boosting_type': 'gbdt',\n",
        "            \n",
        "            # --- D√úZENLENEBƒ∞Lƒ∞R ALAN ---\n",
        "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),     # √ñƒürenme Hƒ±zƒ±\n",
        "            'num_leaves': trial.suggest_int('num_leaves', 20, 150),              # Aƒüa√ß Karma≈üƒ±klƒ±ƒüƒ±\n",
        "            'max_depth': trial.suggest_int('max_depth', 3, 12),                  # Derinlik\n",
        "            'feature_fraction': trial.suggest_float('feature_fraction', 0.5, 1.0), # √ñzellik Kullanƒ±mƒ±\n",
        "            'bagging_fraction': trial.suggest_float('bagging_fraction', 0.5, 1.0), # Veri Kullanƒ±mƒ±\n",
        "            'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n",
        "            'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
        "            # ---------------------------\n",
        "            \n",
        "            'device': 'gpu',\n",
        "            'gpu_platform_id': 0,\n",
        "            'gpu_device_id': 0\n",
        "        }\n",
        "        \n",
        "        # GPU Fallback\n",
        "        try:\n",
        "            train_data = lgb.Dataset(X_train, label=y_train)\n",
        "            val_data = lgb.Dataset(X_val, label=y_val)\n",
        "            model = lgb.train(params, train_data, valid_sets=[val_data], callbacks=[lgb.early_stopping(30)])\n",
        "        except Exception:\n",
        "            params['device'] = 'cpu'\n",
        "            train_data = lgb.Dataset(X_train, label=y_train)\n",
        "            val_data = lgb.Dataset(X_val, label=y_val)\n",
        "            model = lgb.train(params, train_data, valid_sets=[val_data], callbacks=[lgb.early_stopping(30)])\n",
        "\n",
        "        preds = model.predict(X_val)\n",
        "        \n",
        "        # Skorlama (Profit Max)\n",
        "        best_score = -float('inf')\n",
        "        thresholds = np.arange(0.50, 0.99, 0.01)\n",
        "        for thr in thresholds:\n",
        "            pred_labels = (preds > thr).astype(int)\n",
        "            tn, fp, fn, tp = confusion_matrix(y_val, pred_labels).ravel()\n",
        "            score = (tp * scoring['TP']) + (tn * scoring['TN']) - (fp * scoring['FP']) - (fn * scoring['FN'])\n",
        "            if score > best_score: best_score = score\n",
        "        return best_score\n",
        "\n",
        "    # 3. Optuna'yƒ± √áalƒ±≈ütƒ±r\n",
        "    study = optuna.create_study(direction='maximize')\n",
        "    study.optimize(objective, n_trials=epochs)\n",
        "    \n",
        "    print(f\"En ƒ∞yi Parametreler: {study.best_params}\")\n",
        "    \n",
        "    # 4. Final Model ve G√∂rselle≈ütirme\n",
        "    final_params = study.best_params\n",
        "    final_params.update({'metric': 'binary_logloss', 'objective': 'binary', 'verbosity': -1, 'device': 'gpu'})\n",
        "    \n",
        "    final_model = models_avci.train_lgbm(X_train, y_train, X_val, y_val, final_params)\n",
        "    final_model.save_model(f'models/avci_lgbm_{str(target).replace(\".\",\"_\")}.txt')\n",
        "    \n",
        "    visualize_performance(final_model, X_val, y_val, target)\n",
        "    try: optuna.visualization.plot_optimization_history(study).show()\n",
        "    except: pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üïµÔ∏è‚Äç‚ôÇÔ∏è B√∂l√ºm 1: ƒ∞stihbarat & Komuta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if 'model_ae_avci' in locals():\n",
        "    ae = model_ae_avci.train_autoencoder(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if 'model_hmm_avci' in locals():\n",
        "    hmm_model = model_hmm_avci.train_hmm(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ B√∂l√ºm 2: Ni≈üancƒ± Eƒüitimi (LightGBM)\n",
        "A≈üaƒüƒ±daki h√ºcrelerde her hedef i√ßin eƒüitim yapabilirsin."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Veri Setini Hazƒ±rla\n",
        "features = [c for c in df.columns if 'target' not in c and 'result' not in c and 'value' not in c and 'id' not in c]\n",
        "X = df[features]\n",
        "split_idx = int(len(df) * 0.85)\n",
        "X_train, X_val = X.iloc[:split_idx], X.iloc[split_idx:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- 1.50x HEDEFƒ∞ ---\n",
        "run_optuna_for_target(1.5, epochs=30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- 3.00x HEDEFƒ∞ ---\n",
        "run_optuna_for_target(3.0, epochs=30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- 5.00x HEDEFƒ∞ ---\n",
        "run_optuna_for_target(5.0, epochs=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- 10.0x HEDEFƒ∞ ---\n",
        "run_optuna_for_target(10.0, epochs=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- 50.0x HEDEFƒ∞ ---\n",
        "run_optuna_for_target(50.0, epochs=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- 100.0x HEDEFƒ∞ ---\n",
        "run_optuna_for_target(100.0, epochs=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- 1000.0x HEDEFƒ∞ (God Mode) ---\n",
        "run_optuna_for_target(1000.0, epochs=150)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üíæ B√∂l√ºm 3: Modelleri Kaydet ve ƒ∞ndir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# T√ºm Modelleri Ziple\n",
        "import os\n",
        "if not os.path.exists('models'):\n",
        "    os.makedirs('models')\n",
        "    \n",
        "!zip -r avci_models.zip models/\n",
        "\n",
        "# ƒ∞ndir\n",
        "try:\n",
        "    from google.colab import files\n",
        "    files.download('avci_models.zip')\n",
        "    print(\"Dosya indiriliyor... 'avci_models.zip'\")\n",
        "except Exception as e:\n",
        "    print(f\"ƒ∞ndirme hatasƒ±: {e}. Sol taraftaki dosya gezgininden 'avci_models.zip' dosyasƒ±nƒ± saƒü tƒ±klayƒ±p indirebilirsin.\")\n",
        "\n",
        "# Varsa Drive'a Kopyala\n",
        "if os.path.exists('/content/drive/MyDrive'):\n",
        "    !cp avci_models.zip /content/drive/MyDrive/avci_backup_latest.zip\n",
        "    print(\"Yedek Drive'a (Ana Dizin) kopyalandƒ±.\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}