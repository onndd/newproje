{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ğŸ¦… AVCI - YÃ¼ksek Oran AvcÄ±sÄ± EÄŸitim Paneli v6.1.0 (Detailed & Explicit)\n",
        "**GÃ¼ncelleme NotlarÄ±:**\n",
        "- **ğŸ” Åeffaf EÄŸitim:** Optuna kodlarÄ± ve ayarlarÄ± artÄ±k hÃ¼crelerin iÃ§inde aÃ§Ä±kÃ§a gÃ¶rÃ¼nÃ¼yor. Ä°stediÄŸin gibi mÃ¼dahale edebilirsin.\n",
        "- **âš™ï¸ Tam Kontrol:** Her hedef (1.5x, 3.0x...) iÃ§in deneme sayÄ±sÄ±nÄ± (EPOCHS) ve parametreleri hÃ¼cre iÃ§inde deÄŸiÅŸtirebilirsin.\n",
        "- **Veri KurtarÄ±cÄ± (Data Savior):** Drive yedeklemesi aktif.",
        "\n---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. GitHub Deposunu Ã‡ek ve Kurulum Yap (Temiz Kurulum)\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# 1. KÃ¶k dizine dÃ¶n\n",
        "try:\n",
        "    os.chdir('/content')\n",
        "except:\n",
        "    pass\n",
        "\n",
        "# 2. Varsa eski projeyi SÄ°L (Her ÅŸeyi sÄ±fÄ±rla ki eski hatalar kalmasÄ±n)\n",
        "if os.path.exists('newproje'):\n",
        "    print(\"Eski proje dosyalarÄ± temizleniyor...\")\n",
        "    shutil.rmtree('newproje')\n",
        "\n",
        "# 3. SÄ±fÄ±rdan Ä°ndir\n",
        "print(\"Projeyi GitHub'dan sÄ±fÄ±rdan Ã§ekiyorum...\")\n",
        "!git clone https://github.com/onndd/newproje.git\n",
        "\n",
        "# 4. Ã‡alÄ±ÅŸma dizinine gir\n",
        "if os.path.exists('newproje/avci'):\n",
        "    os.chdir('newproje/avci')\n",
        "    print(f\"âœ… Kurulum BaÅŸarÄ±lÄ±. Ã‡alÄ±ÅŸma Dizini: {os.getcwd()}\")\n",
        "    \n",
        "    # --- VERÄ°TABANI KURTARMA ---\n",
        "    drive_db_path = '/content/drive/MyDrive/newproje/avci/jetx.db'\n",
        "    local_db_path = 'jetx.db'\n",
        "    \n",
        "    if not os.path.exists('/content/drive'):\n",
        "        try:\n",
        "            from google.colab import drive\n",
        "            drive.mount('/content/drive')\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    if os.path.exists(drive_db_path):\n",
        "        print(f\"ğŸ”„ GerÃ§ek VeritabanÄ± Drive'dan kopyalanÄ±yor... ({os.path.getsize(drive_db_path)/1024/1024:.2f} MB)\")\n",
        "        shutil.copy(drive_db_path, local_db_path)\n",
        "        print(\"âœ… VeritabanÄ± gÃ¼ncellendi.\")\n",
        "    else:\n",
        "        print(\"âš ï¸ UYARI: Drive'da 'jetx.db' bulunamadÄ±! LÃ¼tfen dosyanÄ±n yerinde olduÄŸundan emin ol.\")\n",
        "else:\n",
        "    print(\"âŒ HATA: Ä°ndirme baÅŸarÄ±sÄ±z oldu!\")\n",
        "\n",
        "print(\"GPU Durumu:\")\n",
        "!nvidia-smi\n",
        "\n",
        "# KÃ¼tÃ¼phane KurulumlarÄ±\n",
        "!pip install optuna streamlit matplotlib pandas tensorflow hmmlearn plotly lightgbm\n",
        "print(\"Kurulum ve HazÄ±rlÄ±k TamamlandÄ±! ArtÄ±k modÃ¼ller bulunabilir.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2. Veri YÃ¼kleme ve Ayarlar\n",
        "import optuna\n",
        "import logging\n",
        "import sys\n",
        "import os\n",
        "\n",
        "optuna.logging.set_verbosity(optuna.logging.INFO)\n",
        "optuna.logging.get_logger(\"optuna\").addHandler(logging.StreamHandler(sys.stdout))\n",
        "\n",
        "try:\n",
        "    # ModÃ¼lleri iÃ§e aktar (Absolute Import)\n",
        "    import train_avci\n",
        "    import models_avci\n",
        "    import model_ae_avci\n",
        "    import model_hmm_avci\n",
        "    \n",
        "    # FonksiyonlarÄ± kÄ±sayol olarak al\n",
        "    load_and_prep = train_avci.load_and_prep\n",
        "    visualize_performance = train_avci.visualize_performance\n",
        "    get_scoring_params = train_avci.get_scoring_params\n",
        "    \n",
        "    print(\"âœ… ModÃ¼ller baÅŸarÄ±yla yÃ¼klendi!\")\n",
        "except ImportError as e:\n",
        "    print(f\"âŒ HATA: ModÃ¼l import hatasÄ±. Detay: {e}\")\n",
        "\n",
        "if 'load_and_prep' in locals():\n",
        "    try:\n",
        "        df = load_and_prep(limit=100000)\n",
        "        print(f\"Veri HazÄ±r: {len(df)} satÄ±r. (SÃ¼tunlar: {len(df.columns)})\")\n",
        "    except Exception as e:\n",
        "         print(f\"âŒ VERÄ° YÃœKLEME HATASI: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ•µï¸â€â™‚ï¸ BÃ¶lÃ¼m 1: Ä°stihbarat & Komuta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Autoencoder (Anomali DedektÃ¶rÃ¼)\n",
        "if 'model_ae_avci' in locals():\n",
        "    ae = model_ae_avci.train_autoencoder(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# HMM (Piyasa Rejimi)\n",
        "if 'model_hmm_avci' in locals():\n",
        "    hmm_model = model_hmm_avci.train_hmm(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ¯ BÃ¶lÃ¼m 2: NiÅŸancÄ± EÄŸitimi (DetaylÄ± Optuna)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- EÄÄ°TÄ°M AYARLARI ---\n",
        "USE_GPU = True\n",
        "features = [c for c in df.columns if 'target' not in c and 'result' not in c and 'value' not in c and 'id' not in c]\n",
        "X = df[features]\n",
        "\n",
        "# Veri Setini BÃ¶l (Son %15 Test)\n",
        "split_idx = int(len(df) * 0.85)\n",
        "X_train, X_val = X.iloc[:split_idx], X.iloc[split_idx:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ğŸ¯ HEDEF 1.50x EÄÄ°TÄ°MÄ°\n",
        "TARGET = 1.5\n",
        "EPOCHS = 30\n",
        "\n",
        "print(f\"\\nğŸš€ {TARGET}x Hedefi Ä°Ã§in Optuna BaÅŸlatÄ±lÄ±yor...\")\n",
        "y_col = f'target_{str(TARGET).replace(\".\",\"_\")}'\n",
        "y_train, y_val = df[y_col].iloc[:split_idx], df[y_col].iloc[split_idx:]\n",
        "scoring = get_scoring_params(TARGET)\n",
        "\n",
        "# Optuna Study\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(lambda trial: models_avci.objective_lgbm(trial, X_train, y_train, X_val, y_val, scoring, USE_GPU), n_trials=EPOCHS)\n",
        "\n",
        "print(f\"En Ä°yi Skor: {study.best_value}\")\n",
        "print(f\"En Ä°yi Parametreler: {study.best_params}\")\n",
        "\n",
        "# Final Model EÄŸitimi\n",
        "final_params = study.best_params\n",
        "final_params.update({'metric': 'binary_logloss', 'objective': 'binary', 'verbosity': -1})\n",
        "if USE_GPU: \n",
        "    final_params.update({'device': 'gpu', 'gpu_platform_id': 0, 'gpu_device_id': 0})\n",
        "\n",
        "model = models_avci.train_lgbm(X_train, y_train, X_val, y_val, final_params)\n",
        "model.save_model(f'models/avci_lgbm_{str(TARGET).replace(\".\",\"_\")}.txt')\n",
        "\n",
        "# Performans Analizi\n",
        "visualize_performance(model, X_val, y_val, TARGET)\n",
        "try: optuna.visualization.plot_optimization_history(study).show()\n",
        "except: pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ğŸ¯ HEDEF 3.00x EÄÄ°TÄ°MÄ°\n",
        "TARGET = 3.0\n",
        "EPOCHS = 30\n",
        "\n",
        "print(f\"\\nğŸš€ {TARGET}x Hedefi Ä°Ã§in Optuna BaÅŸlatÄ±lÄ±yor...\")\n",
        "y_col = f'target_{str(TARGET).replace(\".\",\"_\")}'\n",
        "y_train, y_val = df[y_col].iloc[:split_idx], df[y_col].iloc[split_idx:]\n",
        "scoring = get_scoring_params(TARGET)\n",
        "\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(lambda trial: models_avci.objective_lgbm(trial, X_train, y_train, X_val, y_val, scoring, USE_GPU), n_trials=EPOCHS)\n",
        "\n",
        "final_params = study.best_params\n",
        "final_params.update({'metric': 'binary_logloss', 'objective': 'binary', 'verbosity': -1})\n",
        "if USE_GPU: final_params.update({'device': 'gpu', 'gpu_platform_id': 0, 'gpu_device_id': 0})\n",
        "\n",
        "model = models_avci.train_lgbm(X_train, y_train, X_val, y_val, final_params)\n",
        "model.save_model(f'models/avci_lgbm_{str(TARGET).replace(\".\",\"_\")}.txt')\n",
        "visualize_performance(model, X_val, y_val, TARGET)\n",
        "try: optuna.visualization.plot_optimization_history(study).show()\n",
        "except: pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ğŸ¯ HEDEF 5.00x EÄÄ°TÄ°MÄ°\n",
        "TARGET = 5.0\n",
        "EPOCHS = 50\n",
        "\n",
        "print(f\"\\nğŸš€ {TARGET}x Hedefi Ä°Ã§in Optuna BaÅŸlatÄ±lÄ±yor...\")\n",
        "y_col = f'target_{str(TARGET).replace(\".\",\"_\")}'\n",
        "y_train, y_val = df[y_col].iloc[:split_idx], df[y_col].iloc[split_idx:]\n",
        "scoring = get_scoring_params(TARGET)\n",
        "\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(lambda trial: models_avci.objective_lgbm(trial, X_train, y_train, X_val, y_val, scoring, USE_GPU), n_trials=EPOCHS)\n",
        "\n",
        "final_params = study.best_params\n",
        "final_params.update({'metric': 'binary_logloss', 'objective': 'binary', 'verbosity': -1})\n",
        "if USE_GPU: final_params.update({'device': 'gpu', 'gpu_platform_id': 0, 'gpu_device_id': 0})\n",
        "\n",
        "model = models_avci.train_lgbm(X_train, y_train, X_val, y_val, final_params)\n",
        "model.save_model(f'models/avci_lgbm_{str(TARGET).replace(\".\",\"_\")}.txt')\n",
        "visualize_performance(model, X_val, y_val, TARGET)\n",
        "try: optuna.visualization.plot_optimization_history(study).show()\n",
        "except: pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ğŸ¯ HEDEF 10.0x EÄÄ°TÄ°MÄ°\n",
        "TARGET = 10.0\n",
        "EPOCHS = 50\n",
        "\n",
        "print(f\"\\nğŸš€ {TARGET}x Hedefi Ä°Ã§in Optuna BaÅŸlatÄ±lÄ±yor...\")\n",
        "y_col = f'target_{str(TARGET).replace(\".\",\"_\")}'\n",
        "y_train, y_val = df[y_col].iloc[:split_idx], df[y_col].iloc[split_idx:]\n",
        "scoring = get_scoring_params(TARGET)\n",
        "\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(lambda trial: models_avci.objective_lgbm(trial, X_train, y_train, X_val, y_val, scoring, USE_GPU), n_trials=EPOCHS)\n",
        "\n",
        "final_params = study.best_params\n",
        "final_params.update({'metric': 'binary_logloss', 'objective': 'binary', 'verbosity': -1})\n",
        "if USE_GPU: final_params.update({'device': 'gpu', 'gpu_platform_id': 0, 'gpu_device_id': 0})\n",
        "\n",
        "model = models_avci.train_lgbm(X_train, y_train, X_val, y_val, final_params)\n",
        "model.save_model(f'models/avci_lgbm_{str(TARGET).replace(\".\",\"_\")}.txt')\n",
        "visualize_performance(model, X_val, y_val, TARGET)\n",
        "try: optuna.visualization.plot_optimization_history(study).show()\n",
        "except: pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ğŸ¯ HEDEF 100.0x EÄÄ°TÄ°MÄ° (AvcÄ± Modu)\n",
        "TARGET = 100.0\n",
        "EPOCHS = 100\n",
        "\n",
        "print(f\"\\nğŸš€ {TARGET}x Hedefi Ä°Ã§in Optuna BaÅŸlatÄ±lÄ±yor...\")\n",
        "y_col = f'target_{str(TARGET).replace(\".\",\"_\")}'\n",
        "y_train, y_val = df[y_col].iloc[:split_idx], df[y_col].iloc[split_idx:]\n",
        "scoring = get_scoring_params(TARGET)\n",
        "\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(lambda trial: models_avci.objective_lgbm(trial, X_train, y_train, X_val, y_val, scoring, USE_GPU), n_trials=EPOCHS)\n",
        "\n",
        "final_params = study.best_params\n",
        "final_params.update({'metric': 'binary_logloss', 'objective': 'binary', 'verbosity': -1})\n",
        "if USE_GPU: final_params.update({'device': 'gpu', 'gpu_platform_id': 0, 'gpu_device_id': 0})\n",
        "\n",
        "model = models_avci.train_lgbm(X_train, y_train, X_val, y_val, final_params)\n",
        "model.save_model(f'models/avci_lgbm_{str(TARGET).replace(\".\",\"_\")}.txt')\n",
        "visualize_performance(model, X_val, y_val, TARGET)\n",
        "try: optuna.visualization.plot_optimization_history(study).show()\n",
        "except: pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# GOD MODE: 1000.0x\n",
        "TARGET = 1000.0\n",
        "EPOCHS = 150\n",
        "\n",
        "print(f\"\\nğŸš€ {TARGET}x Hedefi Ä°Ã§in Optuna BaÅŸlatÄ±lÄ±yor...\")\n",
        "y_col = f'target_{str(TARGET).replace(\".\",\"_\")}'\n",
        "y_train, y_val = df[y_col].iloc[:split_idx], df[y_col].iloc[split_idx:]\n",
        "scoring = get_scoring_params(TARGET)\n",
        "\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(lambda trial: models_avci.objective_lgbm(trial, X_train, y_train, X_val, y_val, scoring, USE_GPU), n_trials=EPOCHS)\n",
        "\n",
        "final_params = study.best_params\n",
        "final_params.update({'metric': 'binary_logloss', 'objective': 'binary', 'verbosity': -1})\n",
        "if USE_GPU: final_params.update({'device': 'gpu', 'gpu_platform_id': 0, 'gpu_device_id': 0})\n",
        "\n",
        "model = models_avci.train_lgbm(X_train, y_train, X_val, y_val, final_params)\n",
        "model.save_model(f'models/avci_lgbm_{str(TARGET).replace(\".\",\"_\")}.txt')\n",
        "visualize_performance(model, X_val, y_val, TARGET)\n",
        "try: optuna.visualization.plot_optimization_history(study).show()\n",
        "except: pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ’¾ BÃ¶lÃ¼m 3: Modelleri Kaydet ve Ä°ndir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TÃ¼m Modelleri Ziple\n",
        "import os\n",
        "if not os.path.exists('models'):\n",
        "    os.makedirs('models')\n",
        "    \n",
        "!zip -r avci_models.zip models/\n",
        "\n",
        "# Ä°ndir\n",
        "try:\n",
        "    from google.colab import files\n",
        "    files.download('avci_models.zip')\n",
        "    print(\"Dosya indiriliyor... 'avci_models.zip'\")\n",
        "except Exception as e:\n",
        "    print(f\"Ä°ndirme hatasÄ±: {e}. Sol taraftaki dosya gezgininden 'avci_models.zip' dosyasÄ±nÄ± saÄŸ tÄ±klayÄ±p indirebilirsin.\")\n",
        "\n",
        "# Varsa Drive'a Kopyala\n",
        "if os.path.exists('/content/drive/MyDrive'):\n",
        "    !cp avci_models.zip /content/drive/MyDrive/avci_backup_latest.zip\n",
        "    print(\"Yedek Drive'a (Ana Dizin) kopyalandÄ±.\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}