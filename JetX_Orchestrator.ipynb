{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Proje Kurulumu ve Güncelleme\n",
                "import os\n",
                "import sys\n",
                "\n",
                "# Google Colab kontrolü\n",
                "try:\n",
                "    from google.colab import drive\n",
                "    IN_COLAB = True\n",
                "except ImportError:\n",
                "    IN_COLAB = False\n",
                "\n",
                "if IN_COLAB:\n",
                "    print(\"Google Colab ortamı algılandı.\")\n",
                "    repo_url = \"https://github.com/onndd/newproje.git\"\n",
                "    project_dir = \"/content/newproje\"\n",
                "    \n",
                "    if os.path.exists(project_dir):\n",
                "        print(\"Proje klasörü mevcut. Güncelleniyor...\")\n",
                "        %cd {project_dir}\n",
                "        !git pull\n",
                "    else:\n",
                "        print(\"Proje klonlanıyor...\")\n",
                "        !git clone {repo_url}\n",
                "        %cd {project_dir}\n",
                "        \n",
                "    # Gerekli kütüphaneler (Optuna eklendi)\n",
                "    print(\"Kütüphaneler yükleniyor...\")\n",
                "    %pip install catboost hmmlearn tensorflow lightgbm scikit-learn optuna\n",
                "    \n",
                "    # Path ayarı\n",
                "    sys.path.append(project_dir)\n",
                "else:\n",
                "    print(\"Yerel ortam algılandı.\")\n",
                "    project_dir = os.getcwd()\n",
                "    sys.path.append(project_dir)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 2. Veri Yükleme\n",
                "import sqlite3\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "from jetx_project.data_loader import load_data\n",
                "from jetx_project.config import DB_PATH\n",
                "\n",
                "print(\"Veri yükleniyor...\")\n",
                "try:\n",
                "    df = load_data(DB_PATH)\n",
                "    print(f\"Toplam {len(df)} veri yüklendi.\")\n",
                "    print(df.head())\n",
                "except Exception as e:\n",
                "    print(f\"Hata: {e}\")\n",
                "    print(\"Lütfen jetx.db dosyasının proje klasöründe olduğundan emin olun.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 3. Psikolojik Modeller (HMM) Eğitimi - SIZINTISIZ (LEAK-FREE)\n",
                "print(\"Psikolojik Modeller (HMM) eğitiliyor...\")\n",
                "from jetx_project.model_hmm import train_hmm_model, predict_hmm_state, save_hmm_model\n",
                "\n",
                "if 'df' in locals() and len(df) > 0:\n",
                "    # --- HMM VERİ SIZINTISI (DATA LEAKAGE) DÜZELTMESİ ---\n",
                "    # HMM'i sadece eğitim verisiyle eğitmeliyiz.\n",
                "    # Test verisini \"görmemeli\".\n",
                "    \n",
                "    # 1. Veriyi Böl (Zaman Serisi Olduğu İçin Karıştırmadan)\n",
                "    train_size = int(len(df) * 0.85)\n",
                "    train_values = df['value'].values[:train_size]\n",
                "    test_values = df['value'].values[train_size:]\n",
                "    \n",
                "    print(f\"HMM Eğitimi için veri ayrıldı: {len(train_values)} örnek (Toplamın %85'i)\")\n",
                "    \n",
                "    # 2. HMM Eğitimi (Sadece Train Seti)\n",
                "    # Log-Transform kullanılarak eğitiliyor (model_hmm.py içinde güncellendi)\n",
                "    hmm_model, hmm_map = train_hmm_model(train_values)\n",
                "    save_hmm_model(hmm_model, hmm_map, output_dir='models')\n",
                "    \n",
                "    # 3. Durum Tahmini (Forward-Only)\n",
                "    # Train seti için tahmin (Model zaten bunu gördü, sorun yok)\n",
                "    train_states = predict_hmm_state(hmm_model, train_values, hmm_map)\n",
                "    \n",
                "    # Test seti için tahmin (Model bunu GÖRMEDİ, sadece öğrendiği parametreleri kullanıyor)\n",
                "    # predict_hmm_state fonksiyonu modeli yeniden eğitmez, sadece tahmin yapar.\n",
                "    test_states = predict_hmm_state(hmm_model, test_values, hmm_map)\n",
                "    \n",
                "    # 4. Birleştirme (Feature Extraction için)\n",
                "    # Artık elimizde tüm veri seti için durumlar var, ama test kısmındaki durumlar\n",
                "    # sadece geçmiş bilgiyle (train parametreleriyle) üretildi.\n",
                "    hmm_states_mapped = np.concatenate([train_states, test_states])\n",
                "    \n",
                "    print(\"HMM Durumları belirlendi.\")\n",
                "    print(f\"Durum Dağılımı: {np.bincount(hmm_states_mapped)}\")\n",
                "else:\n",
                "    print(\"Veri yok, HMM eğitilemedi.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 4. OPTUNA İLE HİPERPARAMETRE OPTİMİZASYONU\n",
                "from jetx_project.optimization import optimize_catboost, optimize_lightgbm\n",
                "from jetx_project.model_a import prepare_model_a_data\n",
                "\n",
                "if 'df' in locals() and len(df) > 500:\n",
                "    print(\"Optimizasyon için veri hazırlanıyor...\")\n",
                "    X, y_p15, y_p3, y_x = prepare_model_a_data(df['value'].values, hmm_states_mapped)\n",
                "    \n",
                "    # Sadece eğitim verisi üzerinde optimizasyon yapalım\n",
                "    split_idx = int(len(X) * 0.85)\n",
                "    X_train_opt = X.iloc[:split_idx]\n",
                "    y_p15_train_opt = y_p15[:split_idx]\n",
                "    \n",
                "    print(\"--- CatBoost Optimizasyonu Başlıyor (GPU) ---\")\n",
                "    # P1.5 için en iyi parametreleri bulalım\n",
                "    best_params_catboost = optimize_catboost(X_train_opt, y_p15_train_opt, n_trials=20)\n",
                "    print(\"Bulunan En İyi Parametreler:\", best_params_catboost)\n",
                "    \n",
                "    # Not: LightGBM optimizasyonu CPU üzerinde çalışır, isteğe bağlı açılabilir.\n",
                "    # best_params_lgb = optimize_lightgbm(X_train_opt, y_p15_train_opt, n_trials=10)\n",
                "else:\n",
                "    print(\"Yeterli veri yok.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 5. Model A (CatBoost) Eğitimi\n",
                "from jetx_project.model_a import train_model_a, save_models\n",
                "from catboost import CatBoostClassifier\n",
                "\n",
                "if 'df' in locals() and len(df) > 500:\n",
                "    print(\"Model A (CatBoost) eğitiliyor...\")\n",
                "    # train_model_a fonksiyonu şu an sabit parametreler kullanıyor.\n",
                "    # Ancak biz optimize edilmiş parametreleri kullanmak istiyoruz.\n",
                "    # Bu yüzden burada manuel eğitim yapabiliriz veya train_model_a'yı güncelleyebiliriz.\n",
                "    # Şimdilik standart eğitimi çalıştıralım, ama ileride parametreleri enjekte edebiliriz.\n",
                "    # (Not: optimize_catboost zaten en iyi parametreleri yazdırdı, manuel olarak koda eklenebilir)\n",
                "    \n",
                "    # TODO: best_params_catboost'u train_model_a'ya geçirmek için kodu güncellemek gerekebilir.\n",
                "    # Şimdilik varsayılan (iyileştirilmiş) ayarlarla devam ediyoruz.\n",
                "    modelA_p15, modelA_p3, modelA_x = train_model_a(X, y_p15, y_p3, y_x)\n",
                "    save_models(modelA_p15, modelA_p3, modelA_x, output_dir='models')\n",
                "    print(\"Model A tamamlandı.\")\n",
                "else:\n",
                "    print(\"Yeterli veri yok.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 6. Model B (k-NN) Eğitimi - OPTİMİZE EDİLMİŞ (PCA)\n",
                "from jetx_project.model_b import build_memory, train_model_b, save_memory\n",
                "\n",
                "if 'df' in locals() and len(df) > 500:\n",
                "    print(\"Model B (Hafıza) oluşturuluyor...\")\n",
                "    patterns, targets = build_memory(df['value'].values)\n",
                "    \n",
                "    # Artık PCA nesnesini de döndürüyor\n",
                "    nbrs, pca = train_model_b(patterns)\n",
                "    \n",
                "    save_memory(nbrs, pca, patterns, targets, output_dir='models')\n",
                "    print(\"Model B tamamlandı (PCA ile optimize edildi).\")\n",
                "else:\n",
                "    print(\"Yeterli veri yok.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 7. Model C (LSTM) Eğitimi - SIZINTISIZ\n",
                "from jetx_project.model_lstm import train_model_lstm, save_lstm_models\n",
                "\n",
                "if 'df' in locals() and len(df) > 500:\n",
                "    print(\"Model C (LSTM) eğitiliyor...\")\n",
                "    # LSTM için veriyi kendi içinde hazırlar (Artık kronolojik split kullanıyor)\n",
                "    modelC_p15, modelC_p3, scaler_lstm = train_model_lstm(df['value'].values)\n",
                "    save_lstm_models(modelC_p15, modelC_p3, scaler_lstm, output_dir='models')\n",
                "    print(\"Model C tamamlandı.\")\n",
                "else:\n",
                "    print(\"Yeterli veri yok.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 8. Model D (LightGBM) Eğitimi\n",
                "from jetx_project.model_lightgbm import train_model_lightgbm, save_lightgbm_models\n",
                "\n",
                "if 'df' in locals() and len(df) > 500:\n",
                "    print(\"Model D (LightGBM) eğitiliyor...\")\n",
                "    # Model A ile aynı feature setini kullanır\n",
                "    modelD_p15, modelD_p3 = train_model_lightgbm(X, y_p15, y_p3)\n",
                "    save_lightgbm_models(modelD_p15, modelD_p3, output_dir='models')\n",
                "    print(\"Model D tamamlandı.\")\n",
                "else:\n",
                "    print(\"Yeterli veri yok.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 9. Model E (MLP) Eğitimi\n",
                "from jetx_project.model_mlp import train_model_mlp, save_mlp_models\n",
                "\n",
                "if 'df' in locals() and len(df) > 500:\n",
                "    print(\"Model E (MLP) eğitiliyor...\")\n",
                "    # Model A ile aynı feature setini kullanır ama içinde filtreler\n",
                "    modelE_p15, modelE_p3, mlp_cols = train_model_mlp(X, y_p15, y_p3)\n",
                "    save_mlp_models(modelE_p15, modelE_p3, mlp_cols, output_dir='models')\n",
                "    print(\"Model E tamamlandı.\")\n",
                "else:\n",
                "    print(\"Yeterli veri yok.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 9.5. ENSEMBLE STACKING (Meta-Learner) Eğitimi\n",
                "from jetx_project.ensemble import prepare_meta_features, train_meta_learner, save_meta_learner\n",
                "from jetx_project.model_lstm import create_sequences\n",
                "\n",
                "if 'df' in locals() and len(df) > 2000:\n",
                "    print(\"--- Ensemble Stacking (Meta-Learner) Eğitiliyor ---\")\n",
                "    \n",
                "    # Meta-Learner için VALIDATION setini kullanmalıyız.\n",
                "    # Train setini kullanırsak overfitting olur.\n",
                "    # Bu yüzden son %15'lik kısmı (Validation) kullanacağız.\n",
                "    \n",
                "    val_size = int(len(df) * 0.15)\n",
                "    val_start_idx = len(df) - val_size\n",
                "    \n",
                "    # 1. Validation Seti İçin Tahminleri Topla\n",
                "    print(\"Modellerin Validation tahminleri toplanıyor...\")\n",
                "    \n",
                "    # Model A (CatBoost)\n",
                "    X_val_a, _, _, _ = prepare_model_a_data(df['value'].values, hmm_states_mapped, start_index=val_start_idx)\n",
                "    # Hizalama: prepare_model_a_data N-1 döndürür\n",
                "    # Hedeflerimiz de buna uymalı\n",
                "    y_val_true_15 = (df['value'].values[val_start_idx+1:] >= 1.5).astype(int)\n",
                "    \n",
                "    preds_a_val = modelA_p15.predict_proba(X_val_a)[:, 1]\n",
                "    \n",
                "    # Model B (k-NN)\n",
                "    preds_b_val = []\n",
                "    from jetx_project.model_b import create_pattern_vector, predict_model_b\n",
                "    \n",
                "    # PCA nesnesini Cell 6'dan alıyoruz\n",
                "    pca_obj = locals().get('pca', None) \n",
                "    \n",
                "    for i in range(val_start_idx, len(df) - 1):\n",
                "        pat = create_pattern_vector(df['value'].values, i)\n",
                "        if pat is not None:\n",
                "            p15, _, _ = predict_model_b(nbrs, pca_obj, targets, pat)\n",
                "            preds_b_val.append(p15)\n",
                "        else:\n",
                "            preds_b_val.append(0.5)\n",
                "    preds_b_val = np.array(preds_b_val)\n",
                "            \n",
                "    # Model C (LSTM)\n",
                "    seq_len = 200\n",
                "    val_lstm_start = val_start_idx - seq_len\n",
                "    val_values_extended = df['value'].values[val_lstm_start:]\n",
                "    val_values_scaled = scaler_lstm.transform(val_values_extended.reshape(-1, 1))\n",
                "    X_val_lstm, _, _, _ = create_sequences(val_values_scaled, seq_len)\n",
                "    preds_c_val = modelC_p15.predict(X_val_lstm).flatten()\n",
                "    \n",
                "    # Hizalama\n",
                "    min_len = min(len(preds_a_val), len(preds_b_val), len(preds_c_val))\n",
                "    \n",
                "    preds_a_val = preds_a_val[:min_len]\n",
                "    preds_b_val = preds_b_val[:min_len]\n",
                "    preds_c_val = preds_c_val[:min_len]\n",
                "    y_val_true_15 = y_val_true_15[:min_len]\n",
                "    \n",
                "    # Model D (LightGBM)\n",
                "    preds_d_val = modelD_p15.predict_proba(X_val_a[:min_len])[:, 1]\n",
                "    \n",
                "    # Model E (MLP)\n",
                "    X_val_mlp = X_val_a.iloc[:min_len][mlp_cols]\n",
                "    preds_e_val = modelE_p15.predict_proba(X_val_mlp)[:, 1]\n",
                "    \n",
                "    # HMM States (Validation kısmı)\n",
                "    hmm_val = hmm_states_mapped[val_start_idx+1 : val_start_idx+1+min_len]\n",
                "    \n",
                "    # 2. Meta-Features Hazırla\n",
                "    meta_X_val = prepare_meta_features(preds_a_val, preds_b_val, preds_c_val, preds_d_val, preds_e_val, hmm_val)\n",
                "    \n",
                "    # 3. Eğit\n",
                "    meta_model, meta_scaler = train_meta_learner(meta_X_val, y_val_true_15)\n",
                "    save_meta_learner(meta_model, meta_scaler, output_dir='models')\n",
                "    \n",
                "    print(\"Meta-Learner eğitildi ve kaydedildi.\")\n",
                "    print(\"Katsayılar (Hangi modele güveniyor?):\")\n",
                "    print(f\"A (Cat): {meta_model.coef_[0][0]:.3f}, B (KNN): {meta_model.coef_[0][1]:.3f}, C (LSTM): {meta_model.coef_[0][2]:.3f}\")\n",
                "    print(f\"D (LGB): {meta_model.coef_[0][3]:.3f}, E (MLP): {meta_model.coef_[0][4]:.3f}\")\n",
                "else:\n",
                "    print(\"Yeterli veri yok.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 10. BÜYÜK FİNAL: Simülasyon ve Karşılaştırmalı Rapor\n",
                "import matplotlib.pyplot as plt\n",
                "from jetx_project.simulation import run_simulation\n",
                "from jetx_project.evaluation import detailed_evaluation\n",
                "from jetx_project.ensemble import predict_meta\n",
                "\n",
                "if 'df' in locals() and len(df) > 2000:\n",
                "    print(\"--- BÜYÜK FİNAL: Simülasyon Başlıyor ---\")\n",
                "    \n",
                "    test_size = 2000\n",
                "    test_df = df.iloc[-test_size:].copy()\n",
                "    \n",
                "    # --- Model A (CatBoost) Tahminleri ---\n",
                "    print(\"Model A tahmin ediyor...\")\n",
                "    X_test_a, _, _, _ = prepare_model_a_data(df['value'].values, hmm_states_mapped, start_index=len(df)-test_size)\n",
                "    sim_df = test_df.iloc[:-1].copy()\n",
                "    \n",
                "    sim_df['prob_A_1.5'] = modelA_p15.predict_proba(X_test_a)[:, 1]\n",
                "    sim_df['prob_A_3.0'] = modelA_p3.predict_proba(X_test_a)[:, 1]\n",
                "    \n",
                "    # --- Model C (LSTM) Tahminleri ---\n",
                "    print(\"Model C (LSTM) tahmin ediyor...\")\n",
                "    seq_len = 200\n",
                "    raw_values = df['value'].values\n",
                "    start_idx = len(df) - test_size - seq_len\n",
                "    test_values_extended = raw_values[start_idx:]\n",
                "    test_values_scaled = scaler_lstm.transform(test_values_extended.reshape(-1, 1))\n",
                "    X_lstm, _, _, _ = create_sequences(test_values_scaled, seq_len)\n",
                "    \n",
                "    preds_c_p15 = modelC_p15.predict(X_lstm).flatten()\n",
                "    preds_c_p3 = modelC_p3.predict(X_lstm).flatten()\n",
                "    \n",
                "    sim_df['prob_C_1.5'] = preds_c_p15[:-1]\n",
                "    sim_df['prob_C_3.0'] = preds_c_p3[:-1]\n",
                "    \n",
                "    # --- Model D (LightGBM) Tahminleri ---\n",
                "    print(\"Model D (LightGBM) tahmin ediyor...\")\n",
                "    sim_df['prob_D_1.5'] = modelD_p15.predict_proba(X_test_a)[:, 1]\n",
                "    sim_df['prob_D_3.0'] = modelD_p3.predict_proba(X_test_a)[:, 1]\n",
                "    \n",
                "    # --- Model E (MLP) Tahminleri ---\n",
                "    print(\"Model E (MLP) tahmin ediyor...\")\n",
                "    X_test_mlp = X_test_a[mlp_cols]\n",
                "    sim_df['prob_E_1.5'] = modelE_p15.predict_proba(X_test_mlp)[:, 1]\n",
                "    sim_df['prob_E_3.0'] = modelE_p3.predict_proba(X_test_mlp)[:, 1]\n",
                "    \n",
                "    # --- Model B (k-NN) Tahminleri (Simülasyon İçin) ---\n",
                "    print(\"Model B (k-NN) tahmin ediyor...\")\n",
                "    preds_b_sim = []\n",
                "    pca_obj = locals().get('pca', None)\n",
                "    \n",
                "    for i in range(len(df)-test_size, len(df)-1):\n",
                "        pat = create_pattern_vector(df['value'].values, i)\n",
                "        if pat is not None:\n",
                "            p15, _, _ = predict_model_b(nbrs, pca_obj, targets, pat)\n",
                "            preds_b_sim.append(p15)\n",
                "        else:\n",
                "            preds_b_sim.append(0.5)\n",
                "    sim_df['prob_B_1.5'] = preds_b_sim\n",
                "    \n",
                "    # --- ENSEMBLE (Meta-Learner) Tahminleri ---\n",
                "    print(\"Ensemble (Meta-Learner) tahmin ediyor...\")\n",
                "    hmm_sim = hmm_states_mapped[len(df)-test_size+1:]\n",
                "    \n",
                "    meta_X_sim = prepare_meta_features(\n",
                "        sim_df['prob_A_1.5'], \n",
                "        sim_df['prob_B_1.5'], \n",
                "        sim_df['prob_C_1.5'], \n",
                "        sim_df['prob_D_1.5'], \n",
                "        sim_df['prob_E_1.5'], \n",
                "        hmm_sim\n",
                "    )\n",
                "    \n",
                "    sim_df['prob_Ensemble_1.5'] = predict_meta(meta_model, meta_scaler, meta_X_sim)\n",
                "    sim_df['prob_Ensemble_3.0'] = sim_df['prob_A_3.0'] \n",
                "    \n",
                "    # --- DETAYLI DEĞERLENDİRME (Yeni Metod) ---\n",
                "    print(\"\\n--- DETAYLI PERFORMANS ANALİZİ (TP/FP/TN/FN) ---\")\n",
                "    \n",
                "    y_true_15 = (sim_df['value'] >= 1.5).astype(int)\n",
                "    y_true_3 = (sim_df['value'] >= 3.0).astype(int)\n",
                "    \n",
                "    # Model A\n",
                "    detailed_evaluation(y_true_15, sim_df['prob_A_1.5'], threshold=0.65, model_name=\"Model A\", target_name=\"1.5x\")\n",
                "    \n",
                "    # Ensemble\n",
                "    detailed_evaluation(y_true_15, sim_df['prob_Ensemble_1.5'], threshold=0.65, model_name=\"ENSEMBLE (Meta)\", target_name=\"1.5x\")\n",
                "    \n",
                "    # --- SİMÜLASYON KOŞUSU ---\n",
                "    \n",
                "    def run_single_model_sim(name, prob_col_15, prob_col_3):\n",
                "        temp_df = sim_df.copy()\n",
                "        temp_df['prob_1.5'] = temp_df[prob_col_15]\n",
                "        temp_df['prob_3.0'] = temp_df[prob_col_3]\n",
                "        temp_df['pred_value'] = 0 \n",
                "        \n",
                "        print(f\"\\n>>> {name} Simülasyonu <<<\")\n",
                "        run_simulation(temp_df, model_name=name)\n",
                "        \n",
                "    run_single_model_sim(\"Model A (CatBoost)\", 'prob_A_1.5', 'prob_A_3.0')\n",
                "    run_single_model_sim(\"ENSEMBLE (Meta-Learner)\", 'prob_Ensemble_1.5', 'prob_Ensemble_3.0')\n",
                "    \n",
                "    # --- GÜVEN DAĞILIM GRAFİKLERİ ---\n",
                "    print(\"\\n--- Model Güven Dağılımları Hazırlanıyor ---\")\n",
                "    plt.figure(figsize=(15, 6))\n",
                "    \n",
                "    plt.title(\"1.5x Üstü Olasılık Dağılımı (Modeller Ne Kadar Emin?)\")\n",
                "    plt.hist(sim_df['prob_A_1.5'], bins=50, alpha=0.5, label='Model A (CatBoost)')\n",
                "    plt.hist(sim_df['prob_Ensemble_1.5'], bins=50, alpha=0.5, label='ENSEMBLE (Meta)')\n",
                "    plt.axvline(x=0.5, color='k', linestyle='--', label='Kararsızlık Sınırı (0.5)')\n",
                "    plt.axvline(x=0.65, color='r', linestyle='--', label='Hedef Eşik (0.65)')\n",
                "    plt.legend()\n",
                "    plt.show()\n",
                "    \n",
                "else:\n",
                "    print(\"Simülasyon için yeterli veri yok.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 11. Modelleri İndir\n",
                "!zip -r models.zip models/\n",
                "from google.colab import files\n",
                "files.download('models.zip')"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}